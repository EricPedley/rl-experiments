{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "respected-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enormous-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eric\\projects\\rl experiments\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#you need to pip install Box2d for \n",
    "#THE BOX2D ENVS DON'T INSTALL CORRECTLY UNLESS YOU HAVE SWIG INSTALLED\n",
    "#ONE YOU INSTALL SWIG YOU NEED TO REINSTALL GYM\n",
    "#AFTER SWIG YOU NEED TO INSTALL MICROSOFT VISUAL STUDIO BUILD TOOLS WITH THE SDK(THE SDK IS OPTIONAL AT INSTALL BUT YOU NEED IT)\n",
    "try:\n",
    "    env = gym.make(\"CarRacing-v0\")\n",
    "except AttributeError:\n",
    "    print(\"(this is a custom error message written by me) Attribute Error: try installing box2d with 'pip install Box2d'. If you get an error doing that open this file and read the comment above this try/except block\")\n",
    "    exit(1)\n",
    "discount_rate=0.97\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "portuguese-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alpha-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSquaredError(keras.losses.Loss):#just works for one prediction\n",
    "  def call(self, y_true, y_pred):\n",
    "    #print(f\"smd 2, true: {type(y_true)},pred:{type(y_pred)}\")\n",
    "    res = tf.math.squared_difference(tf.reduce_max(y_pred),y_true)\n",
    "    #print(\"smd 2.5\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "taken-chester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 94, 94, 1)         28        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 47, 47, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2209)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 13260     \n",
      "=================================================================\n",
      "Total params: 13,288\n",
      "Trainable params: 13,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#kernel size article: https://medium.com/analytics-vidhya/how-to-choose-the-size-of-the-convolution-filter-or-kernel-size-for-cnn-86a55a1e2d15\n",
    "model = keras.Sequential(layers=[\n",
    "    keras.layers.Conv2D(filters=1,kernel_size=(3,3),activation=\"relu\",input_shape=(96,96,3)),\n",
    "    keras.layers.MaxPool2D(),#we are keeping pool size at the default 2x2 and strides=None\n",
    "    keras.layers.Flatten(),\n",
    "    #https://www.alexirpan.com/public/research/281areport.pdf\n",
    "    #this is an example of an additive q-function\n",
    "    #the output format is this: \n",
    "    #    [steer left, no steer, steer right, accelerate, coast, brake]\n",
    "    #where each value in the shape is the q-value for that action\n",
    "    keras.layers.Dense(6)\n",
    "])\n",
    "model.compile(loss=CustomSquaredError())\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amino-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(state,action,next_state,reward):\n",
    "    next_pred = model.predict(tf.expand_dims(next_state,0))\n",
    "    q_next = next_pred\n",
    "    q_update = reward+discount_rate*q_next\n",
    "    model.train_on_batch(x=tf.expand_dims(state,0),y=q_update)\n",
    "\n",
    "def makeDecision(state):\n",
    "    action_greedy = np.argmax(model.predict(tf.expand_dims(state,0)))\n",
    "    action_random = random.randint(0,3)\n",
    "    return action_greedy if random.random()>epsilon else action_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "furnished-holiday",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -48.932625 -164.10951  -155.2628     68.47785   380.82953   -79.54268 ]\n"
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "for episode in range(episodes):\n",
    "    done=False\n",
    "    state = env.reset()\n",
    "    iteration=0\n",
    "    while not done:\n",
    "        action = model.predict(tf.expand_dims(state,0))[0]\n",
    "        print(action)\n",
    "        steerAction = np.argmax(action[0:3])\n",
    "        pedalAction = np.argmax(action[3:6])\n",
    "        usableAction = [steerAction-1,1 if pedalAction==0 else 0, 1 if pedalAction==2 else 0]\n",
    "        #action should be a 3-tuple like this: [steer, gas, brake]\n",
    "        next_state, reward, done, info = env.step(usableAction)#reward is one if the goal is reached and zero if the goal isn't reached\n",
    "        #train(state,action,next_state,reward)\n",
    "        state=next_state\n",
    "        #train((state,action,next_state,reward,done))\n",
    "        #print(reward)\n",
    "        env.render()\n",
    "        clear_output(wait=True)\n",
    "print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-albert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
